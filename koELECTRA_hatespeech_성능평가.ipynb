{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvf9vJrsJw71",
        "outputId": "b339af44-5afc-41e1-f456-082a2ed07973"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd \"/content/drive/MyDrive\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd KoELECTRA_new/finetune"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgaIkODbKHAA",
        "outputId": "28dbbd11-8267-4bcd-92d3-c239d8e47644"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/KoELECTRA_new/finetune\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nE_k5glwKLkf",
        "outputId": "39e3c652-0cb4-4286-f381-4162c135ac15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.29.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install seqeval\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWstGX0VLiII",
        "outputId": "77f5ef07-4a44-4dd4-ef69-efcf825a34a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import json\n",
        "import logging\n",
        "import os\n",
        "import glob\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from fastprogress.fastprogress import master_bar, progress_bar\n",
        "\n",
        "from transformers import (\n",
        "    AdamW,\n",
        "    get_linear_schedule_with_warmup\n",
        ")\n",
        "\n",
        "from src import (\n",
        "    CONFIG_CLASSES,\n",
        "    TOKENIZER_CLASSES,\n",
        "    MODEL_FOR_SEQUENCE_CLASSIFICATION,\n",
        "    init_logger,\n",
        "    set_seed,\n",
        "    compute_metrics\n",
        ")\n",
        "from processor import seq_cls_load_and_cache_examples as load_and_cache_examples\n",
        "from processor import seq_cls_tasks_num_labels as tasks_num_labels\n",
        "from processor import seq_cls_processors as processors\n",
        "from processor import seq_cls_output_modes as output_modes\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n"
      ],
      "metadata": {
        "id": "hWoqmBSJKOZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Hyperparameters:\n",
        "    def __init__(self):\n",
        "        self.task = \"hate-speech\"\n",
        "        self.data_dir = \"data\"\n",
        "        self.ckpt_dir = \"ckpt\"\n",
        "        self.train_file = \"train.tsv\"\n",
        "        self.dev_file = \"dev.tsv\"\n",
        "        self.test_file = \"val.tsv\"\n",
        "        self.evaluate_test_during_training = False\n",
        "        self.eval_all_checkpoints = False\n",
        "        self.save_optimizer = False\n",
        "        self.do_lower_case = False\n",
        "        self.do_train = False\n",
        "        self.do_eval = True\n",
        "        self.max_seq_len = 128\n",
        "        self.num_train_epochs = 10\n",
        "        self.weight_decay = 0.0\n",
        "        self.gradient_accumulation_steps = 1\n",
        "        self.adam_epsilon = 1e-8\n",
        "        self.warmup_proportion = 0\n",
        "        self.max_steps = -1\n",
        "        self.max_grad_norm = 1.0\n",
        "        self.no_cuda = False\n",
        "        self.model_type = \"koelectra-base-v3\"\n",
        "        self.model_name_or_path = \"Haaaaeun/koELECTRA_hatespeech_v4\"\n",
        "        self.output_dir = \"koelectra-base-v3-hate-speech-ckpt\"\n",
        "        self.seed = 42\n",
        "        self.train_batch_size = 32\n",
        "        self.eval_batch_size = 64\n",
        "        self.logging_steps = 100\n",
        "        self.save_steps = 100\n",
        "        self.learning_rate = 5e-5\n",
        "        self.device = \"\"\n",
        "\n",
        "\n",
        "args = Hyperparameters()\n",
        "print(args.task)  # 출력: \"hate-speech\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7YRQk7FPNKe",
        "outputId": "c2f0e395-0a44-4a97-b895-240503258143"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hate-speech\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU or CPU\n",
        "args.device = \"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\""
      ],
      "metadata": {
        "id": "xgbquuGlKRM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "eQq6c5EwKTU5",
        "outputId": "1df7fe9d-65e1-47fa-daee-1e949a647a66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "model_name = \"Haaaaeun/koELECTRA_hatespeech_v4\"\n",
        "\n",
        "# Load the tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n"
      ],
      "metadata": {
        "id": "eJ2uC8n-4qgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(args, model, eval_dataset, mode, global_step=None):\n",
        "    results = {}\n",
        "    eval_sampler = SequentialSampler(eval_dataset)\n",
        "    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size)\n",
        "\n",
        "    # Eval!\n",
        "    if global_step != None:\n",
        "        logger.info(\"***** Running evaluation on {} dataset ({} step) *****\".format(mode, global_step))\n",
        "    else:\n",
        "        logger.info(\"***** Running evaluation on {} dataset *****\".format(mode))\n",
        "    logger.info(\"  Num examples = {}\".format(len(eval_dataset)))\n",
        "    logger.info(\"  Eval Batch size = {}\".format(args.eval_batch_size))\n",
        "    eval_loss = 0.0\n",
        "    nb_eval_steps = 0\n",
        "    preds = None\n",
        "    out_label_ids = None\n",
        "\n",
        "    for batch in progress_bar(eval_dataloader):\n",
        "        model.eval()\n",
        "        batch = tuple(t.to(args.device) for t in batch)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            inputs = {\n",
        "                \"input_ids\": batch[0],\n",
        "                \"attention_mask\": batch[1],\n",
        "                \"labels\": batch[3]\n",
        "            }\n",
        "            if args.model_type not in [\"distilkobert\", \"xlm-roberta\"]:\n",
        "                inputs[\"token_type_ids\"] = batch[2]  # Distilkobert, XLM-Roberta don't use segment_ids\n",
        "            outputs = model(**inputs)\n",
        "            tmp_eval_loss, logits = outputs[:2]\n",
        "\n",
        "            eval_loss += tmp_eval_loss.mean().item()\n",
        "        nb_eval_steps += 1\n",
        "        if preds is None:\n",
        "            preds = logits.detach().cpu().numpy()\n",
        "            out_label_ids = inputs[\"labels\"].detach().cpu().numpy()\n",
        "        else:\n",
        "            preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
        "            out_label_ids = np.append(out_label_ids, inputs[\"labels\"].detach().cpu().numpy(), axis=0)\n",
        "\n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "    if output_modes[args.task] == \"classification\":\n",
        "        preds = np.argmax(preds, axis=1)\n",
        "    elif output_modes[args.task] == \"regression\":\n",
        "        preds = np.squeeze(preds)\n",
        "    result = compute_metrics(args.task, out_label_ids, preds)\n",
        "    accuracy = accuracy_score(out_label_ids, preds)\n",
        "    precision = precision_score(out_label_ids, preds)\n",
        "    recall = recall_score(out_label_ids, preds)\n",
        "    auc_roc = roc_auc_score(out_label_ids, preds)\n",
        "\n",
        "    results.update(result)\n",
        "    results.update({\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"auc_roc\": auc_roc})\n",
        "\n",
        "    output_dir = os.path.join(args.output_dir, mode)\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    output_eval_file = os.path.join(output_dir, \"{}-{}.txt\".format(mode, global_step) if global_step else \"{}.txt\".format(mode))\n",
        "    with open(output_eval_file, \"w\") as f_w:\n",
        "        logger.info(\"***** Eval results on {} dataset *****\".format(mode))\n",
        "        for key in sorted(results.keys()):\n",
        "            logger.info(\"  {} = {}\".format(key, str(results[key])))\n",
        "            f_w.write(\"  {} = {}\\n\".format(key, str(results[key])))\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "dtSHgra-Rr79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(args,\n",
        "          model,\n",
        "          train_dataset,\n",
        "          dev_dataset=None,\n",
        "          test_dataset=None):\n",
        "    train_sampler = RandomSampler(train_dataset)\n",
        "    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=args.train_batch_size)\n",
        "    if args.max_steps > 0:\n",
        "        t_total = args.max_steps\n",
        "        args.num_train_epochs = args.max_steps // (len(train_dataloader) // args.gradient_accumulation_steps) + 1\n",
        "    else:\n",
        "        t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n",
        "\n",
        "    # Prepare optimizer and schedule (linear warmup and decay)\n",
        "    no_decay = ['bias', 'LayerNorm.weight']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "         'weight_decay': args.weight_decay},\n",
        "        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "    ]\n",
        "    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(t_total * args.warmup_proportion), num_training_steps=t_total)\n",
        "\n",
        "    if os.path.isfile(os.path.join(args.model_name_or_path, \"optimizer.pt\")) and os.path.isfile(\n",
        "            os.path.join(args.model_name_or_path, \"scheduler.pt\")\n",
        "    ):\n",
        "        # Load optimizer and scheduler states\n",
        "        optimizer.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"optimizer.pt\")))\n",
        "        scheduler.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"scheduler.pt\")))\n",
        "\n",
        "    # Train!\n",
        "    logger.info(\"***** Running training *****\")\n",
        "    logger.info(\"  Num examples = %d\", len(train_dataset))\n",
        "    logger.info(\"  Num Epochs = %d\", args.num_train_epochs)\n",
        "    logger.info(\"  Total train batch size = %d\", args.train_batch_size)\n",
        "    logger.info(\"  Gradient Accumulation steps = %d\", args.gradient_accumulation_steps)\n",
        "    logger.info(\"  Total optimization steps = %d\", t_total)\n",
        "    logger.info(\"  Logging steps = %d\", args.logging_steps)\n",
        "    logger.info(\"  Save steps = %d\", args.save_steps)\n",
        "\n",
        "    global_step = 0\n",
        "    tr_loss = 0.0\n",
        "\n",
        "    model.zero_grad()\n",
        "    mb = master_bar(range(int(args.num_train_epochs)))\n",
        "    for epoch in mb:\n",
        "        epoch_iterator = progress_bar(train_dataloader, parent=mb)\n",
        "        for step, batch in enumerate(epoch_iterator):\n",
        "            model.train()\n",
        "            batch = tuple(t.to(args.device) for t in batch)\n",
        "            inputs = {\n",
        "                \"input_ids\": batch[0],\n",
        "                \"attention_mask\": batch[1],\n",
        "                \"labels\": batch[3]\n",
        "            }\n",
        "            if args.model_type not in [\"distilkobert\", \"xlm-roberta\"]:\n",
        "                inputs[\"token_type_ids\"] = batch[2]  # Distilkobert, XLM-Roberta don't use segment_ids\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "            loss = outputs[0]\n",
        "\n",
        "            if args.gradient_accumulation_steps > 1:\n",
        "                loss = loss / args.gradient_accumulation_steps\n",
        "\n",
        "            loss.backward()\n",
        "            tr_loss += loss.item()\n",
        "            if (step + 1) % args.gradient_accumulation_steps == 0 or (\n",
        "                    len(train_dataloader) <= args.gradient_accumulation_steps\n",
        "                    and (step + 1) == len(train_dataloader)\n",
        "            ):\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
        "\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "                model.zero_grad()\n",
        "                global_step += 1\n",
        "\n",
        "                if args.logging_steps > 0 and global_step % args.logging_steps == 0:\n",
        "                    if args.evaluate_test_during_training:\n",
        "                        evaluate(args, model, test_dataset, \"test\", global_step)\n",
        "                    else:\n",
        "                        evaluate(args, model, dev_dataset, \"dev\", global_step)\n",
        "\n",
        "                if args.save_steps > 0 and global_step % args.save_steps == 0:\n",
        "                    # Save model checkpoint\n",
        "                    output_dir = os.path.join(args.output_dir, \"checkpoint-{}\".format(global_step))\n",
        "                    if not os.path.exists(output_dir):\n",
        "                        os.makedirs(output_dir)\n",
        "                    model_to_save = (\n",
        "                        model.module if hasattr(model, \"module\") else model\n",
        "                    )\n",
        "                    model_to_save.save_pretrained(output_dir)\n",
        "\n",
        "                    torch.save(args, os.path.join(output_dir, \"training_args.bin\"))\n",
        "                    logger.info(\"Saving model checkpoint to {}\".format(output_dir))\n",
        "\n",
        "                    if args.save_optimizer:\n",
        "                        torch.save(optimizer.state_dict(), os.path.join(output_dir, \"optimizer.pt\"))\n",
        "                        torch.save(scheduler.state_dict(), os.path.join(output_dir, \"scheduler.pt\"))\n",
        "                        logger.info(\"Saving optimizer and scheduler states to {}\".format(output_dir))\n",
        "\n",
        "            if args.max_steps > 0 and global_step > args.max_steps:\n",
        "                break\n",
        "\n",
        "        mb.write(\"Epoch {} done\".format(epoch + 1))\n",
        "\n",
        "        if args.max_steps > 0 and global_step > args.max_steps:\n",
        "            break\n",
        "\n",
        "    return global_step, tr_loss / global_step\n",
        "\n"
      ],
      "metadata": {
        "id": "ft8JtqvMhCK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    logger.info(\"Training/evaluation parameters {}\".format(args))\n",
        "\n",
        "    args.output_dir = os.path.join(args.ckpt_dir, args.output_dir)\n",
        "\n",
        "    init_logger()\n",
        "    set_seed(args)\n",
        "\n",
        "    processor = processors[args.task](args)\n",
        "    labels = processor.get_labels()\n",
        "    if output_modes[args.task] == \"regression\":\n",
        "        config = CONFIG_CLASSES[args.model_type].from_pretrained(\n",
        "            args.model_name_or_path,\n",
        "            num_labels=tasks_num_labels[args.task]\n",
        "        )\n",
        "    else:\n",
        "        config = CONFIG_CLASSES[args.model_type].from_pretrained(\n",
        "            args.model_name_or_path,\n",
        "            num_labels=tasks_num_labels[args.task],\n",
        "            id2label={str(i): label for i, label in enumerate(labels)},\n",
        "            label2id={label: i for i, label in enumerate(labels)},\n",
        "        )\n",
        "    tokenizer = TOKENIZER_CLASSES[args.model_type].from_pretrained(\n",
        "        args.model_name_or_path,\n",
        "        do_lower_case=args.do_lower_case\n",
        "    )\n",
        "    model = MODEL_FOR_SEQUENCE_CLASSIFICATION[args.model_type].from_pretrained(\n",
        "        args.model_name_or_path,\n",
        "        config=config\n",
        "    )\n",
        "\n",
        "    # GPU or CPU\n",
        "    args.device = \"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\"\n",
        "    model.to(args.device)\n",
        "\n",
        "    # Load dataset\n",
        "    train_dataset = load_and_cache_examples(args, tokenizer, mode=\"train\") if args.train_file else None\n",
        "    dev_dataset = load_and_cache_examples(args, tokenizer, mode=\"dev\") if args.dev_file else None\n",
        "    test_dataset = load_and_cache_examples(args, tokenizer, mode=\"test\") if args.test_file else None\n",
        "\n",
        "    if dev_dataset == None:\n",
        "        args.evaluate_test_during_training = True  # If there is no dev dataset, only use testset\n",
        "\n",
        "    if args.do_train:\n",
        "        global_step, tr_loss = train(args, model, train_dataset, dev_dataset, test_dataset)\n",
        "        logger.info(\" global_step = {}, average loss = {}\".format(global_step, tr_loss))\n",
        "\n",
        "    results = {}\n",
        "    if args.do_eval:\n",
        "        checkpoint_to_evaluate = '/content/drive/MyDrive/KoELECTRA_new/finetune/ckpt/koelectra-base-v3-hate-speech-ckpt/checkpoint-4700'\n",
        "        \n",
        "        model = MODEL_FOR_SEQUENCE_CLASSIFICATION[args.model_type].from_pretrained(checkpoint_to_evaluate)\n",
        "        model.to(args.device)\n",
        "        result = evaluate(args, model, dev_dataset, mode=\"dev\", global_step=\"4700\")\n",
        "        result = dict((k + \"_4700\", v) for k, v in result.items())\n",
        "        results.update(result)\n",
        "\n",
        "        output_eval_file = os.path.join(args.output_dir, \"eval_results.txt\")\n",
        "        with open(output_eval_file, \"w\") as f_w:\n",
        "            for key in sorted(results.keys()):\n",
        "                f_w.write(\"{} = {}\\n\".format(key, str(results[key])))\n",
        "\n",
        "        # checkpoints = list(os.path.dirname(c) for c in\n",
        "        #                    sorted(glob.glob(args.output_dir + \"/**/\" + \"pytorch_model.bin\", recursive=True),\n",
        "        #                           key=lambda path_with_step: list(map(int, re.findall(r\"\\d+\", path_with_step)))[-1]))\n",
        "        # if not args.eval_all_checkpoints:\n",
        "        #     checkpoints = checkpoints[-1:]\n",
        "        # else:\n",
        "        #     logging.getLogger(\"transformers.configuration_utils\").setLevel(logging.WARN)  # Reduce logging\n",
        "        #     logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.WARN)  # Reduce logging\n",
        "        # logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n",
        "        # for checkpoint in checkpoints:\n",
        "        #     global_step = checkpoint.split(\"-\")[-1]\n",
        "        #     model = MODEL_FOR_SEQUENCE_CLASSIFICATION[args.model_type].from_pretrained(checkpoint)\n",
        "        #     model.to(args.device)\n",
        "        #     result = evaluate(args, model, test_dataset, mode=\"test\", global_step=global_step)\n",
        "        #     result = dict((k + \"_{}\".format(global_step), v) for k, v in result.items())\n",
        "        #     results.update(result)\n",
        "\n",
        "        # output_eval_file = os.path.join(args.output_dir, \"eval_results.txt\")\n",
        "        # with open(output_eval_file, \"w\") as f_w:\n",
        "        #     if len(checkpoints) > 1:\n",
        "        #         for key in sorted(results.keys(), key=lambda key_with_step: (\n",
        "        #                 \"\".join(re.findall(r'[^_]+_', key_with_step)),\n",
        "        #                 int(re.findall(r\"_\\d+\", key_with_step)[-1][1:])\n",
        "        #         )):\n",
        "        #             f_w.write(\"{} = {}\\n\".format(key, str(results[key])))\n",
        "        #     else:\n",
        "        #         for key in sorted(results.keys()):\n",
        "        #             f_w.write(\"{} = {}\\n\".format(key, str(results[key])))\n",
        "\n"
      ],
      "metadata": {
        "id": "6aPwOybCRvQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "hMMJLJVsRyMv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "151f86c4-0113-4ad1-fe81-c6659ef37964"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='1209' class='' max='1209' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [1209/1209 10:05&lt;00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7rzbjqAtR0qK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}